
<!-- I am a final-year Ph.D. student of Zhejiang University, supervised by [Prof. Siliang Tang（汤斯亮）](https://person.zju.edu.cn/siliang/684099.html). Meanwhile, I am a research intern in AntGroup mentored by [YongChao Liu]().

My research interest includes Self-Supervised Graph Representation Learning, Graph Transfer Learning, Domain Generalization, Large Language Models and Graph Foundation Models. -->

<!-- We have proposed the first model-agnostic recipe for improving OOD generalization of graph contrastive learning ([MARIO](https://github.com/ZhuYun97/MARIO/tree/main)), and the first self-aligned graph contrastive learning framework ([RoSA](https://github.com/ZhuYun97/RoSA)).

Recently, we propose an efficient tuning and inference algorithm for LLMs on textual graphs, named [ENGINE](https://arxiv.org/abs/2401.15569), which effectively and efficiently combine GNN and LLMs through a side structure. -->

<!-- We release the [first survey of GraphRAG]() which formalize the GraphRAG workflow, encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced Generation. 

Recently, we propose a new [Graph Foundation Model]() which has strong cross-domain/task transferability.

I am expected to graduate in June 2025 and seeking postdoctoral job opportunities. Please feel free to [contact me](zhuyun_dcd@zju.edu.cn) if you are interested! -->


I am a final-year Ph.D. student at Zhejiang University under the supervision of [Prof. Siliang Tang (汤斯亮)](https://person.zju.edu.cn/siliang/684099.html), and a research intern at AntGroup, mentored by [Yongchao Liu (刘永超)](https://yongchao-liu.github.io/). My research centers on two primary areas: (1) Graph-related studies, including Self-Supervised Graph Representation Learning and Graph Foundation Models, and (2) LLM-related studies, encompassing Efference Inference, Post-Training, and GraphRAG. Additionally, I explore integrating the strengths of these fields to advance model reasoning, with a particular emphasis on GraphRAG and text-attributed graph foundation models.

Specifically, we recently published the [first comprehensive survey on GraphRAG](https://arxiv.org/abs/2408.08921), which formalizes the GraphRAG workflow. Moreover, we introduced a novel [Graph Foundation Model](https://arxiv.org/abs/2410.10329), leveraging LLMs to achieve remarkable cross-domain and cross-task transferability.

I expect to graduate in June 2025 and will join [Shanghai AI Lab](https://www.shlab.org.cn/) as a Junior Researcher. 
<!-- If interested, please feel free to [contact me](zhuyun_dcd@zju.edu.cn). -->
